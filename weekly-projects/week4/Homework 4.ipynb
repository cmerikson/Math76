{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d276d1d-5661-4fcc-ae90-8326c5f74765",
   "metadata": {},
   "source": [
    "Christian Erikson\n",
    "\n",
    "Math 76 Homework 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58735d16-cb06-47ba-ac58-c608b9d06f78",
   "metadata": {},
   "source": [
    "# Decision trees, interpretability, and algorithmic bias\n",
    "\n",
    "## Objective\n",
    "\n",
    "In this week's project, you will explore the COMPAS data set. COMPAS stands for \"Correctional Offender Management Profiling for Alternative Sanctions\". It is a software/algorithm that is used to assess the risk of a registered offender is going to commit another offense. Although researchers and journalists have pointed to [various problems](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing) of this algorithm over many years, the algorithm is still used to inform sentences and parole decisions in several US states. \n",
    "You can learn more about the COMPAS data set [here](https://www.propublica.org/datastore/dataset/compas-recidivism-risk-score-data-and-analysis). \n",
    "\n",
    "Through this project, you will practice fitting and validating several classification models and you will explore some distinct benefits of using decision trees in machine learning. As part of that exploration, you are going to audit your model for demographic biases via a \"closed box\" and an \"open box\" approach.\n",
    "\n",
    "The COMPAS data set is a favorite example among critics of machine learning because it demonstrates several shortcomings and failure modes of machine learning techniques. The lessons learned from this project might be discouraging, and they are important. Keep in mind, however, that what you see here does not generalize to all data sets. \n",
    "\n",
    "This project has four parts.\n",
    "\n",
    "### Part 1: Prepare the COMPAS data set  (PARTIALLY YOU TO COMPLETE)\n",
    "\n",
    "In this part, you will load the COMPAS data set, explore its content, and select several variables as features (i.e., queries) or class labels (i.e., responses). Some of these features are not numerical, so you will need to replace some categorical values with zeros and ones. Your features will include categorical variable with more than two categories. You will uses 1-hot encoding to include this feature in your data set. \n",
    "\n",
    "This part includes four steps:\n",
    "1. Load and explore data set\n",
    "2. Select features and response variables\n",
    "3. Construct numerical coding for categorical features\n",
    "4. Split the data\n",
    "\n",
    "### Part 2: Train and validate a decision tree  (PARTIALLY YOU TO COMPLETE)\n",
    "\n",
    "In this part, you will fit a decision tree to your data. You will examine the effect of tuning the complexity of the tree via the \"maximum number of leaves\" parameter and use 5-fold cross-validation to find an optimal value.\n",
    "\n",
    "This part includes three steps:\n",
    "\n",
    "1. Fit a decision tree on the training data\n",
    "2. Tune the parameter \"maximum number of leaves\"\n",
    "3. Calculate the selected model's test performance\n",
    "\n",
    "\n",
    "### Part 3: Auditing a decision tree for demographic biases  (PARTIALLY YOU TO COMPLETE)\n",
    "\n",
    "Your training data includes several demographic variables (i.e., age, sex, race). A crude way to assess whether a model has some demographic bias is to remove the corresponding variables from your training data and explore how that removal affects your model's performance. Decision trees have the advantage of being interpretable machine learning models. By going through the decision nodes (i.e., branching points), you can \"open the black box and look inside\". Specifically, you can assess how each feature is used in the decision making process.\n",
    "\n",
    "This part includes three steps:\n",
    "\n",
    "1. Fit a decision tree\n",
    "2. Check for racial bias via performance assessment\n",
    "3. Check for racial bias via decision rules\n",
    "\n",
    "### Part 4: Comparison to other linear classifiers (FOR YOU TO COMPLETE)\n",
    "\n",
    "For some types of data, decision trees tend to achieve lower prediction accuracies In this part, you will train and tune several classifiers on the COMPAS data. You will then compare their performance on your test set.\n",
    "\n",
    "This part includes three steps:\n",
    "\n",
    "1. Fit LDA and logistic regression\n",
    "2. Tune and fit ensemble methods\n",
    "3. Tune and fit SVC\n",
    "4. Compare performance metrics for all models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf61d6ee-6086-420a-a1b3-9002b2d292b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b14b03-f395-4bb0-abce-f67293c4a5db",
   "metadata": {},
   "source": [
    "## Part 1: Prepare the COMPAS data set\n",
    "\n",
    ">In this part, you will load the COMPAS data set, explore its content, and select several variables as features (i.e., queries) or class labels (i.e., responses). Some of these features are not numerical, so you will need to replace some categorical values with zeros and ones. Your features will include categorical variable with more than two categories. You will uses 1-hot encoding to include this feature in your data set.\n",
    ">\n",
    ">This part includes four steps:\n",
    ">1. Load and explore data set\n",
    ">2. Select features and response variables\n",
    ">3. Construct numerical coding for categorical features\n",
    ">4. Split the data\n",
    "\n",
    "\n",
    "\n",
    "### Part 1, Step 1: Load and explore data set\n",
    "\n",
    "This folder includes the 'compas-scores-two-years.csv' file. The COMPAS data that you will use for this project is in this file. It is always a good idea to look at the raw data before proceeding with one's machine learning pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f35e4e7-8eab-44b2-a03f-5ed100f53516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'name', 'first', 'last', 'compas_screening_date', 'sex', 'dob',\n",
      "       'age', 'age_cat', 'race', 'juv_fel_count', 'decile_score',\n",
      "       'juv_misd_count', 'juv_other_count', 'priors_count',\n",
      "       'days_b_screening_arrest', 'c_jail_in', 'c_jail_out', 'c_case_number',\n",
      "       'c_offense_date', 'c_arrest_date', 'c_days_from_compas',\n",
      "       'c_charge_degree', 'c_charge_desc', 'is_recid', 'r_case_number',\n",
      "       'r_charge_degree', 'r_days_from_arrest', 'r_offense_date',\n",
      "       'r_charge_desc', 'r_jail_in', 'r_jail_out', 'violent_recid',\n",
      "       'is_violent_recid', 'vr_case_number', 'vr_charge_degree',\n",
      "       'vr_offense_date', 'vr_charge_desc', 'type_of_assessment',\n",
      "       'decile_score.1', 'score_text', 'screening_date',\n",
      "       'v_type_of_assessment', 'v_decile_score', 'v_score_text',\n",
      "       'v_screening_date', 'in_custody', 'out_custody', 'priors_count.1',\n",
      "       'start', 'end', 'event', 'two_year_recid'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>compas_screening_date</th>\n",
       "      <th>sex</th>\n",
       "      <th>dob</th>\n",
       "      <th>age</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>race</th>\n",
       "      <th>...</th>\n",
       "      <th>v_decile_score</th>\n",
       "      <th>v_score_text</th>\n",
       "      <th>v_screening_date</th>\n",
       "      <th>in_custody</th>\n",
       "      <th>out_custody</th>\n",
       "      <th>priors_count.1</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>event</th>\n",
       "      <th>two_year_recid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>miguel hernandez</td>\n",
       "      <td>miguel</td>\n",
       "      <td>hernandez</td>\n",
       "      <td>2013-08-14</td>\n",
       "      <td>Male</td>\n",
       "      <td>1947-04-18</td>\n",
       "      <td>69</td>\n",
       "      <td>Greater than 45</td>\n",
       "      <td>Other</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-08-14</td>\n",
       "      <td>2014-07-07</td>\n",
       "      <td>2014-07-14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>327</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>kevon dixon</td>\n",
       "      <td>kevon</td>\n",
       "      <td>dixon</td>\n",
       "      <td>2013-01-27</td>\n",
       "      <td>Male</td>\n",
       "      <td>1982-01-22</td>\n",
       "      <td>34</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-01-27</td>\n",
       "      <td>2013-01-26</td>\n",
       "      <td>2013-02-05</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>ed philo</td>\n",
       "      <td>ed</td>\n",
       "      <td>philo</td>\n",
       "      <td>2013-04-14</td>\n",
       "      <td>Male</td>\n",
       "      <td>1991-05-14</td>\n",
       "      <td>24</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-04-14</td>\n",
       "      <td>2013-06-16</td>\n",
       "      <td>2013-06-16</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>marcu brown</td>\n",
       "      <td>marcu</td>\n",
       "      <td>brown</td>\n",
       "      <td>2013-01-13</td>\n",
       "      <td>Male</td>\n",
       "      <td>1993-01-21</td>\n",
       "      <td>23</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2013-01-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>bouthy pierrelouis</td>\n",
       "      <td>bouthy</td>\n",
       "      <td>pierrelouis</td>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>Male</td>\n",
       "      <td>1973-01-22</td>\n",
       "      <td>43</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Other</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                name   first         last compas_screening_date   sex  \\\n",
       "0   1    miguel hernandez  miguel    hernandez            2013-08-14  Male   \n",
       "1   3         kevon dixon   kevon        dixon            2013-01-27  Male   \n",
       "2   4            ed philo      ed        philo            2013-04-14  Male   \n",
       "3   5         marcu brown   marcu        brown            2013-01-13  Male   \n",
       "4   6  bouthy pierrelouis  bouthy  pierrelouis            2013-03-26  Male   \n",
       "\n",
       "          dob  age          age_cat              race  ...  v_decile_score  \\\n",
       "0  1947-04-18   69  Greater than 45             Other  ...               1   \n",
       "1  1982-01-22   34          25 - 45  African-American  ...               1   \n",
       "2  1991-05-14   24     Less than 25  African-American  ...               3   \n",
       "3  1993-01-21   23     Less than 25  African-American  ...               6   \n",
       "4  1973-01-22   43          25 - 45             Other  ...               1   \n",
       "\n",
       "   v_score_text  v_screening_date  in_custody  out_custody  priors_count.1  \\\n",
       "0           Low        2013-08-14  2014-07-07   2014-07-14               0   \n",
       "1           Low        2013-01-27  2013-01-26   2013-02-05               0   \n",
       "2           Low        2013-04-14  2013-06-16   2013-06-16               4   \n",
       "3        Medium        2013-01-13         NaN          NaN               1   \n",
       "4           Low        2013-03-26         NaN          NaN               2   \n",
       "\n",
       "  start   end event two_year_recid  \n",
       "0     0   327     0              0  \n",
       "1     9   159     1              1  \n",
       "2     0    63     0              1  \n",
       "3     0  1174     0              0  \n",
       "4     0  1102     0              0  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "raw_data = pd.read_csv('compas-scores-two-years.csv')\n",
    "# print a list of variable names\n",
    "print(raw_data.columns)\n",
    "# look at the first 5 rows \n",
    "raw_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc0cb9b-f285-4da2-8c5e-bd3af43ee4d7",
   "metadata": {},
   "source": [
    "The data set includes 53 variables. There are different types of information. Some variables\n",
    "* personal data (e.g., name, first name (\"first\"), last name (\"last\")) \n",
    "* demographic data (i.e., sex, age, age category (\"age_cat\"), and race)\n",
    "* related to the person's history of commited offenses (e.g., juvenile felony count (\"juv_fel_count\"), juvenile misdemeanor count (\"juv_misd_count\"), and prior offenses count (\"priors-count\"))\n",
    "* related to the charge against the person (e.g., charge offense date (\"c_offense_date\"), charge arrest date (\"c_arrest_date\"), charge degree (\"c_charge_degree\"), and description of charge (\"c_charge_desc\"))\n",
    "* recidivism scores assigned by the COMPAS algorithm (e.g., \"decile_score\", \"score_text\", \"v_decile_score\", \"v_score_text\")\n",
    "* related to an actual recidivism charge (e.g., degree of recidivism charge (\"r_charge_degree\"), data of recidivism offense (\"r_offense_date\"), description of recidivism charge (\"r_charge_desc\"))\n",
    "* related to an actual violent recidivism charge (e.g., degree of violent recidivism charge (\"vr_charge_degree\"), data of violent recidivism offense (\"vr_offense_date\"), description of violent recidivism charge (\"vr_charge_desc\")).\n",
    "\n",
    "### Part 1, Step 2: Select features and response variables\n",
    "\n",
    "The ProPublica article was assessing bias in the COMPAS scores. Here, you will ignore the COMPAS scores and instead explore the challenges of predicting recidivism based on the survey data. What variables seem like sensible predictors? What variables would be sensible outcome variables? The code in the cell below selects some numerical and categorical variables for you to include in your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2fcba38-1f99-4723-96d2-ddf46ac7f7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features and response variables\n",
    "\n",
    "# Features by type\n",
    "numerical_features = ['juv_misd_count', 'juv_other_count', 'juv_fel_count', \n",
    "    'priors_count', 'age']\n",
    "binary_categorical_features = ['sex', 'c_charge_degree']\n",
    "other_categorical_features = ['race']\n",
    "all_features = binary_categorical_features + other_categorical_features + numerical_features\n",
    "\n",
    "# Possible esponse variables\n",
    "response_variables = ['is_recid', 'is_violent_recid', 'two_year_recid']\n",
    "\n",
    "# Variables that are used for data cleaning\n",
    "check_variables = ['days_b_screening_arrest']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b0cbaa-0a7b-46bf-a6d6-25f7c13fc1c7",
   "metadata": {},
   "source": [
    "ProPublica filtered some observations (i.e., rows in the data frame). See their explanation below. Let's follow their procedure.\n",
    "\n",
    "\n",
    "> There are a number of reasons remove rows because of missing data:\n",
    ">\n",
    "> * If the charge date of a defendants Compas scored crime was not within 30 days from when the person was arrested, we assume that because of data quality reasons, that we do not have the right offense.\n",
    "> * We coded the recidivist flag -- is_recid -- to be -1 if we could not find a compas case at all.\n",
    "> * In a similar vein, ordinary traffic offenses -- those with a c_charge_degree of 'O' -- will not result in Jail time are removed (only two of them).\n",
    "> * We filtered the underlying data from Broward county to include only those rows representing people who had either recidivated in two years, or had at least two years outside of a correctional facility.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e11c07da-04e6-42be-b407-31569d56fbcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe has 6172 rows and 11 columns.\n"
     ]
    }
   ],
   "source": [
    "# Subselect data\n",
    "df = raw_data[all_features+response_variables+check_variables]\n",
    "\n",
    "# Apply filters\n",
    "df = df[(df['days_b_screening_arrest'] <= 30) & \n",
    "        (df['days_b_screening_arrest'] >= -30) & \n",
    "        (df['is_recid'] != -1) & \n",
    "        (df['c_charge_degree'] != 'O')]\n",
    "\n",
    "df = df[all_features+response_variables]\n",
    "print('Dataframe has {} rows and {} columns.'.format(df.shape[0], df.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c24fa48-c751-4786-b0d6-54a25be38350",
   "metadata": {},
   "source": [
    "### Part 1, Step 3: Construct numerical coding for categorical features\n",
    "\n",
    "Some of these features in the subselected data are not numerical, so you will need to replace some categorical values with zeros and ones. Your features will include \"race\", which was surveyed as a one categorical variable with more than two categories. You will uses [1-hot encoding](https://en.wikipedia.org/wiki/One-hot) to include this feature in your data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0fdd6d1-8ead-41ff-a9e6-6ce9149fc545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replace Male with 0.\n",
      "Replace Female with 1.\n",
      "Replace M with 0.\n",
      "Replace F with 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cmeri\\AppData\\Local\\Temp\\ipykernel_29840\\1287833026.py:5: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(value, new_value)\n"
     ]
    }
   ],
   "source": [
    "# Code binary features as 0 and 1\n",
    "for x in binary_categorical_features:\n",
    "    for new_value, value in enumerate(set(df[x])):\n",
    "        print(\"Replace {} with {}.\".format(value, new_value))\n",
    "        df = df.replace(value, new_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f026e54b-d977-4ee3-93b8-d47703af9213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>c_charge_degree</th>\n",
       "      <th>race</th>\n",
       "      <th>race_is_Caucasian</th>\n",
       "      <th>race_is_Asian</th>\n",
       "      <th>race_is_Native American</th>\n",
       "      <th>race_is_African-American</th>\n",
       "      <th>race_is_Other</th>\n",
       "      <th>race_is_Hispanic</th>\n",
       "      <th>juv_misd_count</th>\n",
       "      <th>juv_other_count</th>\n",
       "      <th>juv_fel_count</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>age</th>\n",
       "      <th>is_recid</th>\n",
       "      <th>is_violent_recid</th>\n",
       "      <th>two_year_recid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Other</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>African-American</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>African-American</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Other</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Other</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>African-American</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sex  c_charge_degree              race  race_is_Caucasian  race_is_Asian  \\\n",
       "0     0                1             Other              False          False   \n",
       "1     0                1  African-American              False          False   \n",
       "2     0                1  African-American              False          False   \n",
       "5     0                0             Other              False          False   \n",
       "6     0                1         Caucasian               True          False   \n",
       "7     0                1             Other              False          False   \n",
       "8     1                0         Caucasian               True          False   \n",
       "10    0                1         Caucasian               True          False   \n",
       "11    0                0  African-American              False          False   \n",
       "12    1                0         Caucasian               True          False   \n",
       "\n",
       "    race_is_Native American  race_is_African-American  race_is_Other  \\\n",
       "0                     False                     False           True   \n",
       "1                     False                      True          False   \n",
       "2                     False                      True          False   \n",
       "5                     False                     False           True   \n",
       "6                     False                     False          False   \n",
       "7                     False                     False           True   \n",
       "8                     False                     False          False   \n",
       "10                    False                     False          False   \n",
       "11                    False                      True          False   \n",
       "12                    False                     False          False   \n",
       "\n",
       "    race_is_Hispanic  juv_misd_count  juv_other_count  juv_fel_count  \\\n",
       "0              False               0                0              0   \n",
       "1              False               0                0              0   \n",
       "2              False               0                1              0   \n",
       "5              False               0                0              0   \n",
       "6              False               0                0              0   \n",
       "7              False               0                0              0   \n",
       "8              False               0                0              0   \n",
       "10             False               0                0              0   \n",
       "11             False               0                0              0   \n",
       "12             False               0                0              0   \n",
       "\n",
       "    priors_count  age  is_recid  is_violent_recid  two_year_recid  \n",
       "0              0   69         0                 0               0  \n",
       "1              0   34         1                 1               1  \n",
       "2              4   24         1                 0               1  \n",
       "5              0   44         0                 0               0  \n",
       "6             14   41         1                 0               1  \n",
       "7              3   43         0                 0               0  \n",
       "8              0   39         0                 0               0  \n",
       "10             0   27         0                 0               0  \n",
       "11             3   23         1                 0               1  \n",
       "12             0   37         0                 0               0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use 1-hot encoding for other categorical variables\n",
    "one_hot_features = []\n",
    "for x in other_categorical_features:\n",
    "    for new_feature, value in enumerate(set(df[x])):\n",
    "        feature_name = \"{}_is_{}\".format(x,value)\n",
    "        df.insert(3, feature_name, df[x]==value)\n",
    "        one_hot_features += [feature_name]\n",
    "\n",
    "# Check what the data frame looks like now\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731b3c0b-4322-4ec6-80c8-da10665dc72b",
   "metadata": {},
   "source": [
    "### Part 1, Step 4: Split the data\n",
    "\n",
    "Let's collect the features in one data frame and the responses in another data frame. After that, you will set a small portion of the data set aside for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9ea639f-feff-4bf2-ae40-4bfb6714cf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of features\n",
    "features = numerical_features + binary_categorical_features + one_hot_features\n",
    "\n",
    "# features data frame\n",
    "X = df[features]\n",
    "\n",
    "# responses data frame\n",
    "Y = df[response_variables]\n",
    "\n",
    "# Split the data into a training set containing 90% of the data\n",
    "# and test set containing 10% of the data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0556fa-cd30-439d-b671-80e165cfa5d2",
   "metadata": {},
   "source": [
    "# Part 2: Train and validate a decision tree\n",
    "\n",
    ">In this part, you will fit a decision tree to your data. You will examine the effect of tuning the complexity of the tree via the \"maximum number of leaves\" parameter and use 5-fold cross-validation to find an optimal value.\n",
    ">\n",
    ">This part includes three steps:\n",
    ">\n",
    ">1. Fit a decision tree on the training data\n",
    ">2. Tune the parameter \"maximum number of leaves\"\n",
    ">3. Calculate the selected model's test performance\n",
    "\n",
    "### Part 2, Step 1: Fit a decision tree on the training data\n",
    "\n",
    "Start by fitting a decision tree to your training data. Assess its training accuracy and its size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11c2b97d-2348-4e7b-b008-92b99665e9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained decision tree with 2038 leaves and training accuracy 0.79.\n"
     ]
    }
   ],
   "source": [
    "# Create a model\n",
    "model = DecisionTreeClassifier(random_state=7)\n",
    "    \n",
    "# Fit model to training data\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# Evaluate training accuracy\n",
    "y_pred = model.predict(X_train)\n",
    "\n",
    "accuracy = accuracy_score(Y_train, y_pred)\n",
    "\n",
    "# Check size of decision tree\n",
    "num_leaves = model.get_n_leaves()\n",
    "\n",
    "# Report results\n",
    "print('Trained decision tree with {} leaves and training accuracy {:.2f}.'.format(num_leaves, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881e0628-df55-49f3-a00a-123ca44baa98",
   "metadata": {},
   "source": [
    "Your tree has a good training accuracy for the standards of tabular data prediction problems, but its size is enormous! It has so many leaves, that on average every 3 to 4 training observations get a leaf to themselves. It is very probable that this tree is overfitting.\n",
    "\n",
    "### Part 2, Step 2: Tune the parameter \"maximum number of leaves\"\n",
    "\n",
    "Let's try to constrain the complexity of a decision tree during training by setting a value for the argument ``maximum number of leaves``. You can use the sci-kit learn's `cross_val_score` function to quickly assess the out-of-sample performance of trees of varying complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0668136-b649-4b42-be6b-e360ff7d2f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leaves\tMean accuracy\n",
      "---------------------\n",
      "10\t0.550\n",
      "20\t0.582\n",
      "30\t0.593\n",
      "40\t0.592\n",
      "50\t0.585\n",
      "60\t0.583\n",
      "70\t0.584\n",
      "80\t0.582\n",
      "90\t0.583\n",
      "100\t0.581\n",
      "110\t0.580\n",
      "120\t0.579\n",
      "130\t0.578\n",
      "140\t0.578\n",
      "150\t0.579\n",
      "160\t0.579\n",
      "170\t0.577\n",
      "180\t0.578\n",
      "190\t0.574\n",
      "200\t0.573\n",
      "210\t0.574\n",
      "220\t0.572\n",
      "230\t0.571\n",
      "240\t0.570\n",
      "250\t0.570\n",
      "260\t0.568\n",
      "270\t0.568\n",
      "280\t0.567\n",
      "290\t0.565\n",
      "300\t0.565\n",
      "310\t0.565\n",
      "320\t0.566\n",
      "330\t0.565\n",
      "340\t0.562\n",
      "350\t0.563\n",
      "360\t0.560\n",
      "370\t0.560\n",
      "380\t0.559\n",
      "390\t0.559\n",
      "400\t0.558\n",
      "410\t0.555\n",
      "420\t0.553\n",
      "430\t0.551\n",
      "440\t0.551\n",
      "450\t0.553\n",
      "460\t0.555\n",
      "470\t0.554\n",
      "480\t0.552\n",
      "490\t0.551\n",
      "500\t0.550\n",
      "510\t0.551\n",
      "520\t0.551\n",
      "530\t0.550\n",
      "540\t0.549\n",
      "550\t0.548\n",
      "560\t0.548\n",
      "570\t0.548\n",
      "580\t0.547\n",
      "590\t0.548\n",
      "600\t0.547\n",
      "610\t0.546\n",
      "620\t0.544\n",
      "630\t0.544\n",
      "640\t0.545\n",
      "650\t0.545\n",
      "660\t0.546\n",
      "670\t0.546\n",
      "680\t0.545\n",
      "690\t0.541\n",
      "700\t0.541\n",
      "710\t0.541\n",
      "720\t0.542\n",
      "730\t0.541\n",
      "740\t0.541\n",
      "750\t0.541\n",
      "760\t0.541\n",
      "770\t0.539\n",
      "780\t0.537\n",
      "790\t0.537\n",
      "800\t0.535\n",
      "810\t0.535\n",
      "820\t0.535\n",
      "830\t0.532\n",
      "840\t0.532\n",
      "850\t0.531\n",
      "860\t0.531\n",
      "870\t0.531\n",
      "880\t0.530\n",
      "890\t0.530\n",
      "900\t0.529\n",
      "910\t0.527\n",
      "920\t0.527\n",
      "930\t0.526\n",
      "940\t0.527\n",
      "950\t0.527\n",
      "960\t0.527\n",
      "970\t0.527\n",
      "980\t0.529\n",
      "990\t0.528\n",
      "1000\t0.529\n",
      "1010\t0.530\n",
      "1020\t0.530\n",
      "1030\t0.529\n",
      "1040\t0.529\n",
      "1050\t0.528\n",
      "1060\t0.528\n",
      "1070\t0.527\n",
      "1080\t0.527\n",
      "1090\t0.526\n",
      "1100\t0.526\n",
      "1110\t0.525\n",
      "1120\t0.523\n",
      "1130\t0.523\n",
      "1140\t0.524\n",
      "1150\t0.524\n",
      "1160\t0.523\n",
      "1170\t0.523\n",
      "1180\t0.523\n",
      "1190\t0.523\n",
      "1200\t0.523\n",
      "1210\t0.523\n",
      "1220\t0.523\n",
      "1230\t0.521\n",
      "1240\t0.520\n",
      "1250\t0.519\n",
      "1260\t0.519\n",
      "1270\t0.518\n",
      "1280\t0.518\n",
      "1290\t0.517\n",
      "1300\t0.517\n",
      "1310\t0.516\n",
      "1320\t0.517\n",
      "1330\t0.517\n",
      "1340\t0.517\n",
      "1350\t0.516\n",
      "1360\t0.516\n",
      "1370\t0.515\n",
      "1380\t0.515\n",
      "1390\t0.515\n",
      "1400\t0.515\n",
      "1410\t0.515\n",
      "1420\t0.514\n",
      "1430\t0.514\n",
      "1440\t0.513\n",
      "1450\t0.513\n",
      "1460\t0.512\n",
      "1470\t0.512\n",
      "1480\t0.512\n",
      "1490\t0.512\n",
      "1500\t0.512\n",
      "1510\t0.512\n",
      "1520\t0.512\n",
      "1530\t0.512\n",
      "1540\t0.512\n",
      "1550\t0.512\n",
      "1560\t0.512\n",
      "1570\t0.512\n",
      "1580\t0.512\n",
      "1590\t0.512\n",
      "1600\t0.511\n",
      "1610\t0.511\n",
      "1620\t0.510\n",
      "1630\t0.509\n",
      "1640\t0.509\n",
      "1650\t0.509\n",
      "1660\t0.509\n",
      "1670\t0.509\n",
      "1680\t0.509\n",
      "1690\t0.510\n",
      "1700\t0.510\n",
      "1710\t0.510\n",
      "1720\t0.510\n",
      "1730\t0.510\n",
      "1740\t0.510\n",
      "1750\t0.509\n",
      "1760\t0.509\n",
      "1770\t0.509\n",
      "1780\t0.509\n",
      "1790\t0.509\n"
     ]
    }
   ],
   "source": [
    "# Perform 5-fold cross-validation for different tree sizes\n",
    "\n",
    "print('Leaves\\tMean accuracy')\n",
    "print('---------------------')\n",
    "for num_leaves in range(10,1800,10):\n",
    "\n",
    "    # Trees must have at least 2 leaves\n",
    "    if num_leaves >= 2:\n",
    "\n",
    "        # construct a classifier with a limit on its number of leaves\n",
    "        tree = DecisionTreeClassifier(max_leaf_nodes=num_leaves, random_state=7)\n",
    "\n",
    "        # Get validation accuracy via 5-fold cross-validation\n",
    "        scores = cross_val_score(tree, X_train, Y_train, cv=5)\n",
    "    \n",
    "    print(\"{}\\t{:.3f}\".format(num_leaves,scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a46824a-f7f5-4408-94fb-8c463c5a7e0f",
   "metadata": {},
   "source": [
    "Adjust the range of values for `max_leaf_nodes` in the cell above, to identify the best value.\n",
    "\n",
    "### Part 2, Step 3: Calculate the selected model's test performance\n",
    "\n",
    "Train a decision tree using your selected value of `max_leaf_nodes` on the full training set. Assess its accuracy on your test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "502349cb-63ee-4146-8c5e-f58b26241165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained decision tree with 30 leaves and test accuracy 0.59.\n"
     ]
    }
   ],
   "source": [
    "# Create a model\n",
    "model = DecisionTreeClassifier(max_leaf_nodes=30, random_state=7)\n",
    "    \n",
    "# Fit model to training data\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# Evaluate training accuracy\n",
    "Y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "\n",
    "# Check size of decision tree\n",
    "num_leaves = model.get_n_leaves()\n",
    "\n",
    "# Report results\n",
    "print('Trained decision tree with {} leaves and test accuracy {:.2f}.'.format(num_leaves, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415c6b58-4f9e-4d22-b9c0-914b22aea0f9",
   "metadata": {},
   "source": [
    "# Part 3: Auditing a decision tree for demographic biases\n",
    "\n",
    ">Your training data includes several demographic variables (i.e., age, sex, race). A crude way to assess whether a model has some demographic bias is to remove the corresponding variables from your training data and explore how that removal affects your model's performance. Decision trees have the advantage of being interpretable machine learning models. By going through the decision nodes (i.e., branching points), you can \"open the black box and look inside\". Specifically, you can assess how each feature is used in the decision making process.\n",
    ">\n",
    ">This part includes two steps:\n",
    ">\n",
    ">1. Check for racial bias via performance assessment\n",
    ">2. Check for racial bias via decision rules\n",
    "  \n",
    "### Part 3, Step 2: Check for racial bias via performance assessment\n",
    "A simple approach to identifying demographic biases in machine learning is the following: (i) Train and validate the model on the full training set, (ii) train and validate the model on a subset of training variables that excludes the variables related to a potential demographic bias, (iii) compare the results. \n",
    "\n",
    "You have noticed that the validation accuracy of your model can vary for different holdout set selections. To account for these variations, you are going to compare the mean validation accuracy over 100 trees. (You have completed (i) in the previous cell already. Continue now with (ii).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25f5e4e1-5487-4220-afcc-eeb1e228c8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained decision tree with 39 leaves and test accuracy 0.68.\n"
     ]
    }
   ],
   "source": [
    "# Create subset of training data without information on race. \n",
    "# (The information on race was encoded in the one-hot features.)\n",
    "remaining_features = [v for v in X.columns if v not in one_hot_features]\n",
    "X_train_sub = X_train[remaining_features]\n",
    "X_test_sub = X_test[remaining_features]\n",
    "\n",
    "# Create a model\n",
    "dtc = DecisionTreeClassifier(max_leaf_nodes=39)\n",
    "    \n",
    "# Fit model to training data\n",
    "dtc.fit(X_train_sub, Y_train['two_year_recid'])\n",
    "\n",
    "# Evaluate training accuracy\n",
    "y_pred = dtc.predict(X_test_sub)\n",
    "accuracy = (y_pred == Y_test['two_year_recid']).mean()\n",
    "\n",
    "# Check size of decision tree\n",
    "num_leaves = dtc.get_n_leaves()\n",
    "\n",
    "# Report results\n",
    "print('Trained decision tree with {} leaves and test accuracy {:.2f}.'.format(num_leaves, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e10fce-64ad-4f3c-95db-9e31a5e33568",
   "metadata": {},
   "source": [
    "Comparing the mean accuracy values on the all features versus the subselected feature set, what do you conclude about the importance of racial information in this classification problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2525f9fd-d71f-411c-b03f-f06369d57211",
   "metadata": {},
   "source": [
    "The classification accuracy improves when racial information is removed from the dataset. Because it is not needed to achieve accurate scores, it must not be very important to the classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18654ba4-834b-49d8-b110-712844d5bf62",
   "metadata": {},
   "source": [
    "### Part 3, Step 3: Check for racial bias via decision rules\n",
    "The interpretability of decision trees allows for an alternative approach to detecting racial bias. You can simply look at the decision rules. Use the scit-kit learn's function `export_text` to get your decision tree in text format. Compare the decision rules of the your tree with all features and your tree fitted on the subset without racial information. Do you find any indication of racial bias in the decision rules of the first tree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8eef4a9-272d-4df2-8890-c4554fc10821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- priors_count <= 2.50\n",
      "|   |--- age <= 22.50\n",
      "|   |   |--- age <= 20.50\n",
      "|   |   |   |--- age <= 19.50\n",
      "|   |   |   |   |--- class: 1\n",
      "|   |   |   |--- age >  19.50\n",
      "|   |   |   |   |--- priors_count <= 1.50\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- priors_count >  1.50\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |   |--- age >  20.50\n",
      "|   |   |   |--- sex <= 0.50\n",
      "|   |   |   |   |--- priors_count <= 1.50\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- priors_count >  1.50\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |   |   |--- sex >  0.50\n",
      "|   |   |   |   |--- class: 1\n",
      "|   |--- age >  22.50\n",
      "|   |   |--- priors_count <= 0.50\n",
      "|   |   |   |--- age <= 35.50\n",
      "|   |   |   |   |--- sex <= 0.50\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- sex >  0.50\n",
      "|   |   |   |   |   |--- age <= 33.50\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- age >  33.50\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |--- age >  35.50\n",
      "|   |   |   |   |--- class: 1\n",
      "|   |   |--- priors_count >  0.50\n",
      "|   |   |   |--- age <= 32.50\n",
      "|   |   |   |   |--- priors_count <= 1.50\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- priors_count >  1.50\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |   |   |--- age >  32.50\n",
      "|   |   |   |   |--- sex <= 0.50\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- sex >  0.50\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|--- priors_count >  2.50\n",
      "|   |--- age <= 33.50\n",
      "|   |   |--- priors_count <= 7.50\n",
      "|   |   |   |--- c_charge_degree <= 0.50\n",
      "|   |   |   |   |--- class: 1\n",
      "|   |   |   |--- c_charge_degree >  0.50\n",
      "|   |   |   |   |--- age <= 27.50\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- age >  27.50\n",
      "|   |   |   |   |   |--- priors_count <= 5.50\n",
      "|   |   |   |   |   |   |--- sex <= 0.50\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- sex >  0.50\n",
      "|   |   |   |   |   |   |   |--- age <= 32.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- age >  32.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- priors_count >  5.50\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |--- priors_count >  7.50\n",
      "|   |   |   |--- race_is_Other <= 0.50\n",
      "|   |   |   |   |--- class: 1\n",
      "|   |   |   |--- race_is_Other >  0.50\n",
      "|   |   |   |   |--- class: 0\n",
      "|   |--- age >  33.50\n",
      "|   |   |--- priors_count <= 6.50\n",
      "|   |   |   |--- age <= 55.50\n",
      "|   |   |   |   |--- juv_fel_count <= 1.50\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- juv_fel_count >  1.50\n",
      "|   |   |   |   |   |--- class: 0\n",
      "|   |   |   |--- age >  55.50\n",
      "|   |   |   |   |--- class: 1\n",
      "|   |   |--- priors_count >  6.50\n",
      "|   |   |   |--- priors_count <= 13.50\n",
      "|   |   |   |   |--- juv_other_count <= 1.50\n",
      "|   |   |   |   |   |--- age <= 34.50\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- age >  34.50\n",
      "|   |   |   |   |   |   |--- juv_fel_count <= 1.50\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- juv_fel_count >  1.50\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- juv_other_count >  1.50\n",
      "|   |   |   |   |   |--- class: 0\n",
      "|   |   |   |--- priors_count >  13.50\n",
      "|   |   |   |   |--- class: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rules = export_text(model, feature_names=X.columns.tolist())\n",
    "print(rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "212a88fb-f48a-4081-87df-eb1ce5b69bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- priors_count <= 2.50\n",
      "|   |--- age <= 22.50\n",
      "|   |   |--- age <= 20.50\n",
      "|   |   |   |--- priors_count <= 1.50\n",
      "|   |   |   |   |--- age <= 19.50\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- age >  19.50\n",
      "|   |   |   |   |   |--- sex <= 0.50\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- sex >  0.50\n",
      "|   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |--- priors_count >  1.50\n",
      "|   |   |   |   |--- class: 1\n",
      "|   |   |--- age >  20.50\n",
      "|   |   |   |--- sex <= 0.50\n",
      "|   |   |   |   |--- priors_count <= 1.50\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- priors_count >  1.50\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |   |   |--- sex >  0.50\n",
      "|   |   |   |   |--- age <= 21.50\n",
      "|   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |--- age >  21.50\n",
      "|   |   |   |   |   |--- class: 0\n",
      "|   |--- age >  22.50\n",
      "|   |   |--- priors_count <= 0.50\n",
      "|   |   |   |--- age <= 35.50\n",
      "|   |   |   |   |--- sex <= 0.50\n",
      "|   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |--- sex >  0.50\n",
      "|   |   |   |   |   |--- age <= 33.50\n",
      "|   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- age >  33.50\n",
      "|   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |--- age >  35.50\n",
      "|   |   |   |   |--- age <= 52.50\n",
      "|   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |--- age >  52.50\n",
      "|   |   |   |   |   |--- class: 0\n",
      "|   |   |--- priors_count >  0.50\n",
      "|   |   |   |--- age <= 32.50\n",
      "|   |   |   |   |--- priors_count <= 1.50\n",
      "|   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |--- priors_count >  1.50\n",
      "|   |   |   |   |   |--- age <= 24.50\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- age >  24.50\n",
      "|   |   |   |   |   |   |--- sex <= 0.50\n",
      "|   |   |   |   |   |   |   |--- juv_misd_count <= 0.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- juv_misd_count >  0.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- sex >  0.50\n",
      "|   |   |   |   |   |   |   |--- c_charge_degree <= 0.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- c_charge_degree >  0.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |--- age >  32.50\n",
      "|   |   |   |   |--- class: 0\n",
      "|--- priors_count >  2.50\n",
      "|   |--- age <= 33.50\n",
      "|   |   |--- priors_count <= 7.50\n",
      "|   |   |   |--- age <= 27.50\n",
      "|   |   |   |   |--- c_charge_degree <= 0.50\n",
      "|   |   |   |   |   |--- age <= 23.50\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- age >  23.50\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- c_charge_degree >  0.50\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |   |   |--- age >  27.50\n",
      "|   |   |   |   |--- priors_count <= 5.50\n",
      "|   |   |   |   |   |--- sex <= 0.50\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- sex >  0.50\n",
      "|   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |--- priors_count >  5.50\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |   |--- priors_count >  7.50\n",
      "|   |   |   |--- priors_count <= 11.50\n",
      "|   |   |   |   |--- age <= 31.50\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- age >  31.50\n",
      "|   |   |   |   |   |--- c_charge_degree <= 0.50\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- c_charge_degree >  0.50\n",
      "|   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |--- priors_count >  11.50\n",
      "|   |   |   |   |--- class: 1\n",
      "|   |--- age >  33.50\n",
      "|   |   |--- priors_count <= 6.50\n",
      "|   |   |   |--- age <= 55.50\n",
      "|   |   |   |   |--- class: 0\n",
      "|   |   |   |--- age >  55.50\n",
      "|   |   |   |   |--- class: 0\n",
      "|   |   |--- priors_count >  6.50\n",
      "|   |   |   |--- priors_count <= 13.50\n",
      "|   |   |   |   |--- juv_other_count <= 0.50\n",
      "|   |   |   |   |   |--- age <= 34.50\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- age >  34.50\n",
      "|   |   |   |   |   |   |--- juv_fel_count <= 1.50\n",
      "|   |   |   |   |   |   |   |--- juv_misd_count <= 2.50\n",
      "|   |   |   |   |   |   |   |   |--- age <= 70.50\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- age >  70.50\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- juv_misd_count >  2.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- juv_fel_count >  1.50\n",
      "|   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |--- juv_other_count >  0.50\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |   |   |--- priors_count >  13.50\n",
      "|   |   |   |   |--- class: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rules_sub = export_text(dtc, feature_names=X_test_sub.columns.tolist())\n",
    "print(rules_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fdb37e-b79d-4791-ac62-15b1533c0dd5",
   "metadata": {},
   "source": [
    "There is a leaf in the origianl model that splits the data using the race_is_Other feature. Individuals who have Other listed for race are more likely to be classified by the model for recidivism. Thies leaf if not included in the model using a subset of the features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e82dfe8-9fd7-44f9-aca4-8e33f9203798",
   "metadata": {},
   "source": [
    "# Part 4: Comparison to other linear classifiers\n",
    "\n",
    ">For some types of data, decision trees tend to achieve lower prediction accuracies In this part, you will train and tune several classifiers on the COMPAS data. You will then compare their performance on your test set.\n",
    ">\n",
    ">This part includes three steps:\n",
    ">\n",
    ">1. Fit LDA and logistic regression\n",
    ">2. Tune and fit ensemble methods\n",
    ">3. Tune and fit SVC\n",
    ">4. Compare test accuracy of all your models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e904dac-3eed-4341-b5bd-6a26f1e207c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of features\n",
    "features = numerical_features + binary_categorical_features + one_hot_features\n",
    "\n",
    "# features data frame\n",
    "X = df[features]\n",
    "\n",
    "# responses data frame\n",
    "Y = df[response_variables]\n",
    "\n",
    "# Split the data into a training set containing 90% of the data\n",
    "# and test set containing 10% of the data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b0fcdcdc-b5e6-4369-b257-565191c2bb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select one outcome to predict from the Y set\n",
    "Y_train_rec = Y_train.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e97edaf2-04da-4f12-aa8f-75847bd6e3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# LDA\n",
    "scaler = StandardScaler()\n",
    "X_train_st = scaler.fit_transform(X_train)\n",
    "X_test_st = scaler.transform(X_test)\n",
    "\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "\n",
    "lda.fit(X_train_st, Y_train_rec)\n",
    "\n",
    "y_pred_lda = lda.predict(X_test_st)\n",
    "\n",
    "accuracy = accuracy_score(Y_test.iloc[:,0], y_pred_lda)\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    'Method': ['LDA'],\n",
    "    'Score': [accuracy]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "877ce464-62d5-44e0-beef-d69bfd4b6591",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Logistic\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "log_reg.fit(X_train_st, Y_train_rec)\n",
    "\n",
    "# Predict the test set results\n",
    "y_pred_log_reg = log_reg.predict(X_test_st)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_log_reg = accuracy_score(Y_test.iloc[:,0], y_pred_log_reg)\n",
    "\n",
    "new_results = pd.DataFrame({\n",
    "    'Method': ['Logistic Regression'],\n",
    "    'Score': [accuracy_log_reg]\n",
    "})\n",
    "\n",
    "results = pd.concat([results, new_results], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9ac41f32-0601-4160-a23d-6b5765f7c7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 66.83%\n",
      "Gradient Boosting Accuracy: 67.64%\n",
      "Bagging Accuracy: 65.37%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Ensemble Methods\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "param_grid_gb = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'max_depth': [3, 5]\n",
    "}\n",
    "\n",
    "param_grid_bg = {\n",
    "    'n_estimators': [10, 50, 100],\n",
    "    'max_samples': [0.5, 1.0],\n",
    "    'max_features': [0.5, 1.0]\n",
    "}\n",
    "\n",
    "ensemble_methods = {\n",
    "    'Random Forest': (RandomForestClassifier(), param_grid_rf),\n",
    "    'Gradient Boosting': (GradientBoostingClassifier(), param_grid_gb),\n",
    "    'Bagging': (BaggingClassifier(), param_grid_bg)\n",
    "}\n",
    "\n",
    "# 5-fold cross-validation\n",
    "for method_name, (model, param_grid) in ensemble_methods.items():\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(X_train_st, Y_train_rec)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test_st)\n",
    "    accuracy = accuracy_score(Y_test.iloc[:,0], y_pred)\n",
    "    print(f'{method_name} Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "    # Append the results to the DataFrame\n",
    "    new_results = pd.DataFrame({\n",
    "        'Method': [method_name],\n",
    "        'Score': [accuracy]\n",
    "    })\n",
    "    results = pd.concat([results, new_results], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f859ffa8-e249-4c19-a467-95b153a81700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Accuracy: 67.48%\n"
     ]
    }
   ],
   "source": [
    "#SVC\n",
    "param_grid_svc = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': [0.001, 0.01, 0.1],\n",
    "    'kernel': ['rbf', 'linear']\n",
    "}\n",
    "\n",
    "# Perform grid search with 5-fold cross-validation\n",
    "svc = SVC()\n",
    "grid_search = GridSearchCV(svc, param_grid_svc, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train_st, Y_train.iloc[:,0])\n",
    "\n",
    "best_svc = grid_search.best_estimator_\n",
    "\n",
    "y_pred_svc = best_svc.predict(X_test_st)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_svc = accuracy_score(Y_test.iloc[:,0], y_pred_svc)\n",
    "print(f'SVC Accuracy: {accuracy_svc * 100:.2f}%')\n",
    "\n",
    "# Create a DataFrame to store the method and score\n",
    "new_results = pd.DataFrame({\n",
    "    'Method': ['SVC'],\n",
    "    'Score': [accuracy_svc]\n",
    "})\n",
    "results = pd.concat([results, new_results], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2b3b5ce1-24fc-4ea9-a35f-f8b8d72209aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LDA</td>\n",
       "      <td>0.663430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.673139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.668285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.676375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bagging</td>\n",
       "      <td>0.653722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.674757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Method     Score\n",
       "0                  LDA  0.663430\n",
       "1  Logistic Regression  0.673139\n",
       "2        Random Forest  0.668285\n",
       "3    Gradient Boosting  0.676375\n",
       "4              Bagging  0.653722\n",
       "5                  SVC  0.674757"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65d7519-2403-4abc-8b93-3c23ac4c4f1f",
   "metadata": {},
   "source": [
    "Gradient Boosting has the highest test accuracy, although SVC and Logistic Regression perform similarly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aeda160-210e-4049-ad79-eab252bc1ae8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
